{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a5cd15",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "### Glory Odeyemi\n",
    "\n",
    "#### 6-Feb-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134818de",
   "metadata": {},
   "source": [
    "### Install libraries\n",
    "\n",
    "You can skip this step if you already have these libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3d6d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytrec-eval-terrier in /Users/new/opt/anaconda3/lib/python3.9/site-packages (0.5.5)\n",
      "Requirement already satisfied: nltk in /Users/new/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/new/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/new/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/new/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /Users/new/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytrec-eval-terrier\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b03f7",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "This is an important step because some of the codes that depends on these libraries will give an error if the libraries are not imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b20af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import itertools\n",
    "from utils.top_k_success import top_k_tokens, success_at_k, average_k\n",
    "from utils.n_gram_model import tokenize_corpus, train_model, save_model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4318a277",
   "metadata": {},
   "source": [
    "### Download Brown corpus\n",
    "\n",
    "We use the news genre of the brown corpus to train our n-Gram language model in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "642bd45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/new/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/new/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab7b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "# brown.categories()\n",
    "brown_corpus_tokens = brown.words(categories='news')\n",
    "print(brown_corpus_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c6929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the brown corpus news genre =  100554\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of tokens in the brown corpus news genre = \", len(brown_corpus_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9a9d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']]\n"
     ]
    }
   ],
   "source": [
    "brown_corpus_sents = brown.sents(categories='news')\n",
    "print(brown_corpus_sents[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4c8ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences in the brown corpus news genre =  4623\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of sentences in the brown corpus news genre = \", len(brown_corpus_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfc789e",
   "metadata": {},
   "source": [
    "### Import Birkbeck corpus\n",
    "\n",
    "Birkbeck spelling error corpus was used for this project. You can find it [here](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/0643).\n",
    "\n",
    "The [APPLING1DAT.643](https://github.com/gloryodeyemi) file out of the Birkbeck spelling error corpus by Roger Mitton was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b45d31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['$Punjabi'],\n",
       " ['strang', 'strange', 'I', 'felt', 'very', '*'],\n",
       " ['brake', 'break', 'at', '*', 'time'],\n",
       " ['brack', 'break', 'when', 'the', '*', 'was', 'finished'],\n",
       " ['weanter', 'winter', 'in', 'the', '*', 'when', 'it', 'was', 'snowing'],\n",
       " ['gost', 'ghost', 'I', 'thought', 'it', 'was', 'a', '*'],\n",
       " ['expect', 'except', 'everything', '*', 'the', 'houses'],\n",
       " ['$Tamil'],\n",
       " ['steped', 'stepped', 'when', 'I', 'first', '*'],\n",
       " ['streagh', 'strange', 'and', 'saw', '*', 'colow', 'people']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birkbeck_data = []\n",
    "with open('Data/APPLING1DAT.643', 'r') as file_data:\n",
    "    for line in file_data:\n",
    "        data = line.split()\n",
    "        birkbeck_data.append(data)\n",
    "birkbeck_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa67528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['strang', 'strange', 'I', 'felt', 'very', '*'],\n",
       " ['brake', 'break', 'at', '*', 'time'],\n",
       " ['brack', 'break', 'when', 'the', '*', 'was', 'finished'],\n",
       " ['weanter', 'winter', 'in', 'the', '*', 'when', 'it', 'was', 'snowing'],\n",
       " ['gost', 'ghost', 'I', 'thought', 'it', 'was', 'a', '*'],\n",
       " ['expect', 'except', 'everything', '*', 'the', 'houses'],\n",
       " ['steped', 'stepped', 'when', 'I', 'first', '*'],\n",
       " ['streagh', 'strange', 'and', 'saw', '*', 'colow', 'people'],\n",
       " ['colow', 'coloured', 'and', 'saw', 'streagh', '*', 'people'],\n",
       " ['exclation', 'escalator', 'I', 'was', 'on', 'an', '*']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean corpus to remove line with $\n",
    "for ind_list in birkbeck_data:\n",
    "    for item in ind_list:\n",
    "        if(item.startswith('$')):\n",
    "            birkbeck_data.remove(ind_list)\n",
    "        \n",
    "birkbeck_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed275d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of errored words in Birbeck corpus =  198\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of errored words in Birbeck corpus = \", len(birkbeck_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31dc326",
   "metadata": {},
   "source": [
    "### Tokenizing the Brown corpus\n",
    "\n",
    "The brown corpus has to be tokenized before we can use it to train our language models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "046579fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'fulton', 'county', 'grand', 'jury', 'said', 'friday', 'an', 'investigation', 'of', 'atlanta', \"'s\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', '``', 'that', 'any', 'irregularities', 'took', 'place', '.'], ['the', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'city', 'executive', 'committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'city', 'of', 'atlanta', '``', 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = tokenize_corpus(brown_corpus_sents)\n",
    "print(tokenized_corpus[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc41ed7",
   "metadata": {},
   "source": [
    "### Training the language model\n",
    "\n",
    "We will train and save n-Gram language models using the tokenized brown corpus for n={1,2,3,5,10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032cc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = [1, 2, 3, 5, 10]\n",
    "\n",
    "for n in n_list:\n",
    "    model = train_model(n, tokenized_corpus)\n",
    "    save_model(n, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11df6a",
   "metadata": {},
   "source": [
    "### Getting the top-k list of tokens and success at k\n",
    "\n",
    "* Top-k list of tokens are the top most probable list of token that are retrieved by the language model.\n",
    "* For every incorrect word in the birkbeck_data corpus, top-k tokens are returned, where k={1,5,10}.\n",
    "* Success at k (s@k) measures whether the correct spelling of the word in the birkbeck_data corpus happens to be in the top-k (most probable) list of tokens that are retrieved by the language model.\n",
    "\n",
    "**Sample test:** Two items in the birkbeck_data corpus will be used as test and sample result is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b46a2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "1-gram model: \n",
      "--------------\n",
      "Top-k probability: 1 {'correct_word': 'hammer', 'incorrect_word': 'hamer', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Top-k probability: 2 {'correct_word': 'might', 'incorrect_word': 'mite', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Success at k:  {'hamer': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}, 'mite': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}}\n",
      "\n",
      "--------------\n",
      "2-gram model: \n",
      "--------------\n",
      "Top-k probability: 1 {'correct_word': 'hammer', 'incorrect_word': 'hamer', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Top-k probability: 2 {'correct_word': 'might', 'incorrect_word': 'mite', 'top_1': {'are': 0.08633093525179857}, 'top_5': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004}, 'top_10': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004, 'can': 0.039568345323741004, 'would': 0.03597122302158273, 'could': 0.03597122302158273, 'also': 0.025179856115107913, \"'re\": 0.02158273381294964}}\n",
      "\n",
      "Success at k:  {'hamer': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}, 'mite': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}}\n",
      "\n",
      "--------------\n",
      "3-gram model: \n",
      "--------------\n",
      "Top-k probability: 1 {'correct_word': 'hammer', 'incorrect_word': 'hamer', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Top-k probability: 2 {'correct_word': 'might', 'incorrect_word': 'mite', 'top_1': {'are': 0.08633093525179857}, 'top_5': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004}, 'top_10': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004, 'can': 0.039568345323741004, 'would': 0.03597122302158273, 'could': 0.03597122302158273, 'also': 0.025179856115107913, \"'re\": 0.02158273381294964}}\n",
      "\n",
      "Success at k:  {'hamer': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}, 'mite': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}}\n",
      "\n",
      "--------------\n",
      "5-gram model: \n",
      "--------------\n",
      "Top-k probability: 1 {'correct_word': 'hammer', 'incorrect_word': 'hamer', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Top-k probability: 2 {'correct_word': 'might', 'incorrect_word': 'mite', 'top_1': {'are': 0.08633093525179857}, 'top_5': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004}, 'top_10': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004, 'can': 0.039568345323741004, 'would': 0.03597122302158273, 'could': 0.03597122302158273, 'also': 0.025179856115107913, \"'re\": 0.02158273381294964}}\n",
      "\n",
      "Success at k:  {'hamer': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}, 'mite': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}}\n",
      "\n",
      "--------------\n",
      "10-gram model: \n",
      "--------------\n",
      "Top-k probability: 1 {'correct_word': 'hammer', 'incorrect_word': 'hamer', 'top_1': {'the': 0}, 'top_5': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0}, 'top_10': {'the': 0, 'fulton': 0, 'county': 0, 'grand': 0, 'jury': 0, 'said': 0, 'friday': 0, 'an': 0, 'investigation': 0, 'of': 0}}\n",
      "\n",
      "Top-k probability: 2 {'correct_word': 'might', 'incorrect_word': 'mite', 'top_1': {'are': 0.08633093525179857}, 'top_5': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004}, 'top_10': {'are': 0.08633093525179857, 'have': 0.07194244604316546, 'were': 0.07194244604316546, 'had': 0.06115107913669065, 'will': 0.039568345323741004, 'can': 0.039568345323741004, 'would': 0.03597122302158273, 'could': 0.03597122302158273, 'also': 0.025179856115107913, \"'re\": 0.02158273381294964}}\n",
      "\n",
      "Success at k:  {'hamer': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}, 'mite': {'success_at_1': 0, 'success_at_5': 0, 'success_at_10': 0}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_test = birkbeck_data[50:52]\n",
    "top_k_result = []\n",
    "\n",
    "for n in n_list:\n",
    "    model_loaded = load_model(n)\n",
    "    print(\"--------------\")\n",
    "    print(f\"{n}-gram model: \\n--------------\")\n",
    "    for data_row in sample_test:\n",
    "        res = top_k_tokens(data_row, model_loaded, tokenized_corpus)\n",
    "        print(f\"Top-k probability: {sample_test.index(data_row) + 1}\", res)\n",
    "        print(\"\")\n",
    "        top_k_result.append(res)\n",
    "    \n",
    "    success = success_at_k(top_k_result)\n",
    "    print(\"Success at k: \", success)\n",
    "    print(\"\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d630774",
   "metadata": {},
   "source": [
    "### Evaluating all incorrect token in our birkbeck corpus and getting the average success at k for n={1,2,3,5,10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4742e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "1-gram model: \n",
      "--------------\n",
      "Average success at k:  {'success_at_1': 0.0, 'success_at_5': 0.0, 'success_at_10': 0.0}\n",
      "--------------\n",
      "2-gram model: \n",
      "--------------\n",
      "Average success at k:  {'success_at_1': 0.0, 'success_at_5': 0.005235602094240838, 'success_at_10': 0.010471204188481676}\n",
      "--------------\n",
      "3-gram model: \n",
      "--------------\n",
      "Average success at k:  {'success_at_1': 0.010471204188481676, 'success_at_5': 0.020942408376963352, 'success_at_10': 0.02617801047120419}\n",
      "--------------\n",
      "5-gram model: \n",
      "--------------\n",
      "Average success at k:  {'success_at_1': 0.010471204188481676, 'success_at_5': 0.020942408376963352, 'success_at_10': 0.02617801047120419}\n",
      "--------------\n",
      "10-gram model: \n",
      "--------------\n",
      "Average success at k:  {'success_at_1': 0.010471204188481676, 'success_at_5': 0.020942408376963352, 'success_at_10': 0.02617801047120419}\n"
     ]
    }
   ],
   "source": [
    "top_k_result = []\n",
    "\n",
    "for n in n_list:\n",
    "    model_loaded = load_model(n)\n",
    "    print(\"--------------\")\n",
    "    print(f\"{n}-gram model: \\n--------------\")\n",
    "    for data_row in birkbeck_data:\n",
    "        res = top_k_tokens(data_row, model_loaded, tokenized_corpus)\n",
    "        top_k_result.append(res)\n",
    "    \n",
    "    success = success_at_k(top_k_result)\n",
    "    avg = average_k(success)\n",
    "    print(\"Average success at k: \", avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
