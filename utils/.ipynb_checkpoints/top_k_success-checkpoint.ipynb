{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088e0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval as pt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2308482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return top-k most probable list of tokens\n",
    "def top_k_tokens(data_row, model, tokenized_corpus):\n",
    "    cor_word = data_row[1]\n",
    "    incor_word = data_row[0]\n",
    "    sent_to_predict = data_row[2:]\n",
    "    sent_to_predict = ' '.join(sent_to_predict).split('*')\n",
    "    sent_to_predict = sent_to_predict[0]\n",
    "\n",
    "    l_model_result = {'correct_word':cor_word, 'incorrect_word':incor_word}\n",
    "    probs_dict = {}\n",
    "    for sentence in tokenized_corpus:\n",
    "        for token in sentence:             \n",
    "            probability = model.score(token, sent_to_predict.split())\n",
    "            probs_dict[token] = probability\n",
    "        \n",
    "    probs_dict = dict(sorted(probs_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    for k in [1,5,10]:\n",
    "        probs_dict_res = dict(list(probs_dict.items())[:k])\n",
    "        l_model_result['top_' + str(k)] = probs_dict_res\n",
    "    \n",
    "    return l_model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05674851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check for the success at k\n",
    "def check_insert(k_list, correct_word):\n",
    "    if correct_word in k_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d5e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the success at k for top-k most probable word returned\n",
    "def success_at_k(top_k_result):\n",
    "    suc_at_k_dict = {}\n",
    "    result_dict = {}\n",
    "    for item in top_k_result:\n",
    "        correct_word, incorrect_word, top_1, top_5, top_10 = itemgetter('correct_word', 'incorrect_word',\n",
    "                                                                        'top_1', 'top_5', 'top_10')(item)\n",
    "#         correct_word = top_k_result['correct_word']\n",
    "#         incorrect_word = top_k_result['incorrect_word']\n",
    "#         top_1 = top_k_result['top_1']\n",
    "#         top_5 = top_k_result['top_5']\n",
    "#         top_10 = top_k_result['top_10']\n",
    "    \n",
    "        result_dict['success_at_1'] = check_insert(top_1, correct_word)\n",
    "        result_dict['success_at_5'] = check_insert(top_5, correct_word)\n",
    "        result_dict['success_at_10'] = check_insert(top_10, correct_word)\n",
    "\n",
    "        suc_at_k_dict[incorrect_word] = result_dict\n",
    "        result_dict = {}\n",
    "\n",
    "    return suc_at_k_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2410816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calculate average success at k for k={1, 5, 10} using PyTrec_Eval_Terrier\n",
    "def average_k(success_dict):\n",
    "    average_dict = {}\n",
    "    for k_success in success_dict[list(success_dict.keys())[0]].keys():\n",
    "        average_dict[k_success] = pt.compute_aggregated_measure(\n",
    "                                  k_success, [val[k_success] for val in success_dict.values()])\n",
    "    return average_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
